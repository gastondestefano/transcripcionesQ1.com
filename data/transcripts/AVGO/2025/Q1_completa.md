# Broadcom Inc., Conferencia de Resultados del Q1 2025, 06 de marzo de 2025

03/06/25 (Fecha interpretada como 3 de junio de 2025)

**Operador(a)**
Bienvenidos a la Conferencia sobre los Resultados Financieros del Primer Trimestre del Año Fiscal 2025 de Broadcom Inc.
En este momento, para los comentarios de apertura e introducciones, me gustaría ceder la palabra a Ji Yoo, Directora de Relaciones con Inversores de Broadcom Inc.

**Ji Yoo**
Gracias, Sheri, y buenas tardes a todos. Hoy me acompañan en la llamada Hock Tan, Presidente y CEO; Kirsten Spears, Directora Financiera; y Charlie Kawwas, Presidente del Grupo de Soluciones de Semiconductores.

Broadcom distribuyó un comunicado de prensa y tablas financieras después del cierre del mercado, describiendo nuestro desempeño financiero para el primer trimestre del año fiscal 2025. Si no recibieron una copia, pueden obtener la información en la sección de inversores del sitio web de Broadcom en broadcom.com.

Esta conferencia telefónica se está transmitiendo en vivo por webcast y una repetición de audio de la llamada estará accesible durante 1 año a través de la sección de Inversores del sitio web de Broadcom.

Durante los comentarios preparados, Hock y Kirsten proporcionarán detalles de nuestros resultados del primer trimestre del año fiscal 2025, proyecciones para nuestro segundo trimestre del año fiscal 2025, así como comentarios sobre el entorno empresarial. Tomaremos preguntas después del final de nuestros comentarios preparados.

Por favor, consulten nuestro comunicado de prensa de hoy y nuestras recientes presentaciones ante la SEC para obtener información sobre los factores de riesgo específicos que podrían causar que nuestros resultados reales difieran materialmente de las declaraciones prospectivas hechas en esta llamada.

Además de los informes según los U.S. GAAP, Broadcom informa ciertas medidas financieras sobre una base no-GAAP. Se incluye una conciliación entre las medidas GAAP y no-GAAP en las tablas adjuntas al comunicado de prensa de hoy. Los comentarios realizados durante la llamada de hoy se referirán principalmente a nuestros resultados financieros no-GAAP.

Ahora cederé la palabra a Hock.

**Hock Tan**
Gracias, Ji. Y gracias a todos por acompañarnos hoy. En nuestro Q1 fiscal de 2025, los ingresos totales fueron un récord de 14.900 millones de dólares, un aumento del 25% interanual, y el EBITDA ajustado consolidado fue nuevamente un récord, 10.100 millones de dólares, un aumento del 41% interanual.

Permítanme primero darles detalles sobre nuestro negocio de semiconductores. Los ingresos por semiconductores del Q1 fueron de 8.200 millones de dólares, un aumento del 11% interanual. El crecimiento fue impulsado por la IA, ya que los ingresos por IA de 4.100 millones de dólares aumentaron un 77% interanual. Superamos nuestras proyecciones de ingresos por IA de 3.800 millones de dólares debido a envíos más fuertes de soluciones de redes a hiperescaladores en IA. Nuestros socios hiperescaladores continúan invirtiendo agresivamente en sus modelos de frontera de próxima generación, que requieren aceleradores de alto rendimiento, así como centros de datos de IA con clústeres más grandes.

Y en consonancia con esto, estamos aumentando nuestra inversión en I+D en 2 frentes. Uno, estamos superando los límites de la tecnología en la creación de la próxima generación de aceleradores. Estamos lanzando el primer encapsulado XPU de IA de 2 nanómetros 3.5D de la industria mientras avanzamos hacia un XPU de 10.000 teraflops.

En segundo lugar, tenemos una visión hacia la ampliación de clústeres de 500.000 aceleradores para clientes hiperescaladores. Hemos duplicado la capacidad de radix del Tomahawk 5 existente. Y más allá de esto, para permitir que los clústeres de IA escalen en Ethernet hacia 1 millón de XPUs. Hemos lanzado nuestro switch Tomahawk 6 de próxima generación de 100 terabits, que ejecuta estudios de 200G y un ancho de banda de 1.6 terabits. Entregaremos muestras a los clientes en los próximos meses.

Estas inversiones en I+D están muy alineadas con la hoja de ruta de nuestros 3 clientes hiperescaladores, ya que cada uno compite por alcanzar clústeres de 1 millón de XPU para finales de 2027. Y, en consecuencia, reafirmamos lo que dijimos el último trimestre: esperamos que estos 3 clientes hiperescaladores generen un mercado direccionable o SAM en el rango de 60.000 a 90.000 millones de dólares en el año fiscal 2027. Más allá de estos 3 clientes, también mencionamos previamente que estamos profundamente comprometidos con otros 2 hiperescaladores para permitirles crear su propio acelerador de IA personalizado. Estamos en camino de sacar sus XPUs este año.

En el proceso de trabajar con los hiperescaladores, ha quedado muy claro que, si bien son excelentes en software, Broadcom es el mejor en hardware. Trabajar juntos es lo que optimiza mediante grandes modelos de lenguaje. Por lo tanto, no nos sorprende. Desde nuestra última llamada de resultados, 2 hiperescaladores adicionales han seleccionado a Broadcom para desarrollar aceleradores personalizados para entrenar sus modelos de frontera de próxima generación. Así que, aunque tenemos 3 clientes hiperescaladores a los que enviamos XPUs en volumen hoy, ahora hay 4 más que están profundamente comprometidos con nosotros para crear sus propios aceleradores. Y para

ser claros, por supuesto, estos 4 no están incluidos en nuestro SAM estimado de 60.000 a 90.000 millones de dólares en 2027.

Así que vemos una tendencia emocionante aquí. Los nuevos modelos y técnicas de frontera ejercen presiones inesperadas sobre los sistemas de IA. Es difícil servir a todas las clases de modelos con un único punto de diseño de sistema. Y, por lo tanto, es difícil imaginar que un acelerador de propósito general pueda configurarse y optimizarse a través de múltiples modelos de frontera. Y como mencioné antes, la tendencia hacia los XPUs es un viaje de varios años. Volviendo a 2025, vemos un aumento constante en el despliegue de nuestros XPUs y productos de redes. En el Q1, los ingresos por IA fueron de 4.100 millones de dólares, y esperamos que los ingresos por IA del Q2 crezcan a 4.400 millones de dólares, lo que representa un aumento del 44% interanual.

Pasando a los semiconductores no relacionados con la IA. Los ingresos de 4.100 millones de dólares disminuyeron un 9% secuencialmente debido a una disminución estacional en el sector inalámbrico. En conjunto, durante el Q1, la recuperación en los semiconductores no relacionados con la IA continuó siendo lenta. La banda ancha, que tocó fondo en el Q4 de 2024, mostró una recuperación secuencial de dos dígitos en el Q1 y se espera que aumente de manera similar en el Q2 a medida que los proveedores de servicios y las empresas de telecomunicaciones aumenten el gasto. El almacenamiento de servidores disminuyó secuencialmente en un solo dígito en el Q1, pero se espera que aumente secuencialmente en un solo dígito alto en el Q2.

Mientras tanto, las redes empresariales continúan manteniéndose estables en la primera mitad del año fiscal 25, ya que los clientes continúan trabajando con el inventario del canal. Si bien el sector inalámbrico disminuyó secuencialmente debido a una baja estacional, se mantuvo estable interanualmente. En el Q2, se espera que el sector inalámbrico se mantenga igual, nuevamente estable interanualmente.

Las reventas en el sector industrial disminuyeron dos dígitos en el Q1 y se espera que disminuyan en el Q2. Reflejando los pros y contras anteriores, esperamos que los ingresos por semiconductores no relacionados con la IA en el Q2 se mantengan estables secuencialmente, aunque estamos viendo que las reservas continúan creciendo interanualmente. En resumen, para el Q2, esperamos que los ingresos totales por semiconductores crezcan un 2% secuencialmente y un 17% interanual, hasta los 8.400 millones de dólares.

Pasando ahora al segmento de software de infraestructura. Los ingresos por software de infraestructura del Q1 de 6.700 millones de dólares aumentaron un 47% interanual y un 15% secuencialmente, exagerados por acuerdos que se deslizaron del Q2 -- Q4 al Q1. Este es el primer trimestre, Q1 '25, donde las comparables interanuales incluyen VMware en ambos trimestres.

Estamos viendo un crecimiento significativo en el segmento de software por dos razones: Una, estamos convirtiendo una huella de licencias mayoritariamente perpetuas a una de suscripción completa. Y a día de hoy, hemos avanzado más del 60%; dos, estas licencias perpetuas eran en gran medida solo para virtualización de cómputo, también

llamada vSphere. Estamos realizando ventas adicionales a los clientes hacia un VCF de pila completa, que permite virtualizar todo el centro de datos.

Y esto permite a los clientes crear su propio entorno de nube privada on-premise. Y al final del Q1, aproximadamente el 70% de nuestros 10.000 clientes más grandes han adoptado VCF. A medida que estos clientes consumen VCF, vemos una oportunidad adicional para el crecimiento futuro. A medida que las grandes empresas adoptan la IA, tienen que ejecutar sus cargas de trabajo de IA en sus centros de datos on-premise, que incluirán tanto servidores GPU como CPUs tradicionales.

Y así como VCF virtualiza estos centros de datos tradicionales usando CPUs, VCF también virtualizará GPUs en una plataforma común y permitirá a las empresas importar modelos de IA para ejecutar sus propios datos on-premise. Esta plataforma, que virtualizó la GPU, se llama VMware Private AI Foundation. Y a día de hoy, en colaboración con NVIDIA, tenemos 39 clientes empresariales para VMware Private AI Foundation.

La demanda de los clientes ha sido impulsada por nuestro ecosistema abierto, equilibrio de carga superior y capacidades de automatización que les permiten extraer y ejecutar cargas de trabajo de manera inteligente tanto en infraestructura GPU como CPU, lo que lleva a costos muy reducidos.

Pasando a las perspectivas del Q2 para software. Esperamos ingresos de 6.500 millones de dólares, un aumento del 23% interanual. Así que, en total, estamos proyectando ingresos consolidados del Q2 de aproximadamente 14.900 millones de dólares, un aumento del 19% interanual. Y esto esperamos que impulse el EBITDA ajustado del Q2 a aproximadamente el 66% de los ingresos.

Con eso, cederé la palabra a Kirsten.

**Kirsten Spears**
Gracias, Hock. Permítanme ahora proporcionar detalles adicionales sobre nuestro desempeño financiero del Q1. Desde una base comparable interanual, tengan en cuenta que el Q1 del año fiscal 2024 fue un trimestre de 14 semanas y el Q1 del año fiscal 2025 es un trimestre de 13 semanas.

Los ingresos consolidados fueron de 14.900 millones de dólares para el trimestre, un aumento del 25% respecto al año anterior. El margen bruto fue del 79.1% de los ingresos en el trimestre, mejor de lo que habíamos proyectado originalmente debido a mayores ingresos por software de infraestructura y una mezcla de ingresos por semiconductores más favorable.

Los gastos operativos consolidados fueron de 2.000 millones de dólares, de los cuales 1.400 millones fueron para I+D. Los ingresos operativos del Q1 de 9.800 millones de dólares aumentaron un 44% respecto al año anterior, con un margen operativo del 66% de los ingresos.

El EBITDA ajustado fue un récord de 10.100 millones de dólares o el 68% de los ingresos, por encima de nuestra proyección del 66%. Esta cifra excluye 142 millones de dólares de depreciación.

Ahora, una revisión del P&L (Estado de Pérdidas y Ganancias) para nuestros 2 segmentos. Empezando por los semiconductores. Los ingresos para nuestro segmento de soluciones de semiconductores fueron de 8.200 millones de dólares y representaron el 55% de los ingresos totales en el trimestre. Esto supuso un aumento del 11% interanual. El margen bruto para nuestro segmento de soluciones de semiconductores fue aproximadamente del 68%, un aumento de 70 puntos básicos interanual impulsado por la mezcla de ingresos.

Los gastos operativos aumentaron un 3% interanual a 890 millones de dólares debido a una mayor inversión en I+D para semiconductores de IA de vanguardia, lo que resultó en un margen operativo de semiconductores del 57%.

Ahora, pasando al software de infraestructura. Los ingresos por software de infraestructura de 6.700 millones de dólares representaron el 45% de los ingresos totales y aumentaron un 47% interanual, principalmente debido al aumento de los ingresos de VMware. El margen bruto para el software de infraestructura fue del 92.5% en el trimestre, en comparación con el 88% del año anterior. Los gastos operativos fueron aproximadamente de 1.100 millones de dólares en el trimestre, lo que resultó en un margen operativo de software de infraestructura del 76%. Esto se compara con un margen operativo del 59% del año anterior. Esta mejora interanual refleja nuestra integración disciplinada de VMware y un enfoque nítido en la implementación de nuestra estrategia VCF.

Pasando al flujo de caja. El flujo de caja libre en el trimestre fue de 6.000 millones de dólares y representó el 40% de los ingresos. El flujo de caja libre como porcentaje de los ingresos continúa viéndose afectado por los gastos de intereses en efectivo de la deuda relacionada con la adquisición de VMware y los impuestos en efectivo debido a la mezcla de ingresos imponibles en EE. UU., el retraso continuo en la promulgación de la Sección 174 y el impacto del AMT corporativo (Impuesto Mínimo Alternativo). Gastamos 100 millones de dólares en gastos de capital.

Los días de ventas pendientes de cobro (DSO) fueron de 30 días en el primer trimestre en comparación con los 41 días del año anterior. Terminamos el primer trimestre con un inventario de 1.900 millones de dólares, un aumento del 8% secuencialmente para respaldar los ingresos en trimestres futuros. Nuestros días de inventario disponible fueron de 65 días en el Q1, ya que continuamos siendo disciplinados en cómo gestionamos el inventario en todo el ecosistema. Terminamos el primer trimestre con 9.300 millones de dólares en efectivo y 68.800 millones de dólares de deuda principal bruta.

Durante el trimestre, reembolsamos 495 millones de dólares de deuda a tasa fija y 7.600 millones de dólares de deuda a tasa flotante con nuevas notas senior, papel comercial y efectivo disponible, reduciendo la deuda en un neto de 1.100 millones de dólares.

Tras estas acciones, la tasa de cupón promedio ponderada y los años hasta el vencimiento de nuestra deuda a tasa fija de 58.800 millones de dólares son del 3.8% y 7.3 años, respectivamente. La tasa de cupón promedio ponderada y los años hasta el vencimiento de nuestra deuda a tasa flotante de 6.000 millones de dólares son del 5.4%

y 3.8 años, respectivamente, y nuestro papel comercial de 4.000 millones de dólares tiene una tasa promedio del 4.6%.

Pasando a la asignación de capital. En el Q1, pagamos a los accionistas 2.800 millones de dólares en dividendos en efectivo basados en un dividendo trimestral en efectivo por acción ordinaria de 0.59 dólares. Gastamos 2.000 millones de dólares para recomprar 8.7 millones de acciones de AVGO de los empleados a medida que esas acciones se consolidaban para impuestos de retención. En el Q2, esperamos que el recuento de acciones diluidas no-GAAP sea de aproximadamente 4.950 millones de acciones.

Ahora, pasando a las proyecciones. Nuestra proyección para el Q2 es de ingresos consolidados de 14.900 millones de dólares, con ingresos por semiconductores de aproximadamente 8.400 millones de dólares, un aumento del 17% interanual. Esperamos ingresos por IA en el Q2 de 4.400 millones de dólares, un aumento del 44% interanual. Para los semiconductores no relacionados con la IA, esperamos ingresos en el Q2 de 4.000 millones de dólares. Esperamos ingresos por software de infraestructura en el Q2 de aproximadamente 6.500 millones de dólares, un aumento del 23% interanual.

Esperamos que el EBITDA ajustado del Q2 sea de alrededor del 66%. Para fines de modelización, esperamos que el margen bruto consolidado del Q2 disminuya aproximadamente 20 puntos básicos secuencialmente debido a la mezcla de ingresos de software de infraestructura y la mezcla de productos dentro de los semiconductores. Como Hock discutió anteriormente, estamos aumentando nuestra inversión en I+D en IA de vanguardia en el Q2 y, en consecuencia, esperamos que el EBITDA ajustado sea aproximadamente del 66%. Esperamos que la tasa impositiva no-GAAP para el Q2 y el año fiscal 2025 sea aproximadamente del 14%.

Esto concluye mis comentarios preparados. Operador(a), por favor, abra la llamada para preguntas.

**Operador(a)**
[Instrucciones del Operador(a)] Y nuestra primera pregunta vendrá de la línea de Ben Reitzes con Melius.

**Benjamin Reitzes**
Muchas gracias y felicidades por los resultados. Hock, hablaste de 4 clientes más que se están incorporando. ¿Puedes hablar un poco más sobre la tendencia que estás viendo? ¿Alguno de estos clientes puede ser tan grande como los 3 actuales? ¿Y qué dice esto sobre la tendencia general del silicio personalizado y tu optimismo y potencial de crecimiento para el negocio a largo plazo?

**Hock Tan**
Pregunta muy interesante, Ben, y gracias por tus amables deseos. Pero lo que hemos visto es -- y por cierto, estos 4 aún no son clientes como los definimos. Como siempre he dicho, al desarrollar y crear XPUs, no somos realmente los creadores de esos XPUs, para ser honesto. Permitimos que cada uno de esos socios hiperescaladores con los que nos comprometemos cree ese chip y básicamente cree ese sistema de cómputo, llamémoslo así. Y comprende

el modelo, el modelo de software, trabajando estrechamente con el motor de cómputo, el XPU y la red que une los clústeres, esos múltiples XPUs en su conjunto para entrenar esos grandes modelos de frontera.

Y así -- y el hecho de que creemos el hardware, todavía tiene que funcionar con los modelos de software y algoritmos de esos socios nuestros antes de que se vuelva completamente desplegable a escala, por lo que definimos a los clientes en este caso como aquellos en los que sabemos que han desplegado a escala y recibimos el volumen de producción para permitir que funcione. Y para eso, solo tenemos, para reiterar. Los 4, los llamo socios que están tratando de crear lo mismo que los primeros 3 y ejecutar sus propios modelos de frontera, cada uno de ellos no tiene que entrenar sus propios modelos de frontera.

Y como también dije, no sucede de la noche a la mañana. Hacer el primer chip podría llevar -- llevaría típicamente 1.5 años, y eso es muy acelerado y podríamos acelerarlo dado que esencialmente tenemos un marco y una metodología que funciona ahora mismo y funciona para los 3 clientes, no hay razón para que no funcione para 4. Pero todavía necesitamos que esos 4 socios creen y desarrollen el software, que nosotros no hacemos, para que funcione.

Y para responder a tu pregunta, no hay razón por la cual estos 4 tipos no crearían una demanda en el rango de lo que estamos viendo con los primeros 3 tipos, pero probablemente más tarde. Es un viaje. Empezaron más tarde, y probablemente llegarán allí más tarde.

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de Harlan Sur con JPMorgan.

**Harlan Sur**
Gran trabajo en la ejecución trimestral, Hock y equipo. Es fantástico ver el continuo impulso en el negocio de IA aquí en la primera mitad de su año fiscal y la continua ampliación de sus clientes de ASIC de IA. Sé que en la última presentación de resultados, Hock, mencionaste un fuerte aumento en la segunda mitad del año fiscal, impulsado por nuevos programas acelerados de IA de 3 nanómetros que están comenzando a escalar.

¿Puedes ayudarnos a perfilar, ya sea cualitativa o cuantitativamente, el aumento de la segunda mitad en relación con lo que el equipo acaba de entregar aquí en la primera mitad? ¿Ha cambiado el perfil, ya sea favorablemente o menos favorablemente, en comparación con lo que quizás era hace 90 días? Porque, francamente, quiero decir, han pasado muchas cosas desde la última presentación de resultados, ¿verdad? Has tenido dinámicas como DeepSeek y el enfoque en la eficiencia del modelo de IA, pero por otro lado, has tenido fuertes

perspectivas de CapEx por parte de tus clientes de nube e hiperescaladores. Así que cualquier detalle sobre el perfil de IA de la segunda mitad sería útil.

**Hock Tan**
Me pides que lea la mente de mis clientes, y odio decirte que no me lo dicen, no me muestran toda su mentalidad aquí. Pero por qué estamos superando las cifras hasta ahora en el Q1 y parece ser alentador en el Q2, en parte por la mejora de los envíos de redes, como indiqué, para costar esos XPUs en aceleradores de IA, incluso en algunos casos, GPUs junto con los hiperescaladores. Y eso es bueno. Y en parte también, creemos que hay algunos adelantos de envíos y aceleración, llamémoslo así, de envíos en el año fiscal 25.

**Harlan Sur**
Y sobre la segunda mitad, de la que hablaste hace 90 días, ¿el aumento de la producción de 3 nanómetros en la segunda mitad? ¿Sigue eso muy encaminado?

**Hock Tan**
Harlan, gracias. Solo doy proyecciones para el Q2, lo siento. No especulemos sobre la segunda mitad.

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de William Stein con Truist Securities.

**William Stein**
Felicidades por estos excelentes resultados. Parece, por los titulares de las noticias sobre aranceles y sobre DeepSeek, que puede haber algunas interrupciones, algunos clientes y algunos otros proveedores complementarios parecen sentirse un poco paralizados quizás y tener dificultades para tomar decisiones difíciles. Esos suelen ser momentos realmente útiles para que las grandes empresas surjan como algo más grande y mejor de lo que eran en el pasado. Han hecho crecer esta empresa de manera tremenda durante la última década y más, y lo están haciendo muy bien ahora, especialmente en esta área de IA.

Pero me pregunto si están viendo ese tipo de disrupción por estas dinámicas que sospechamos que están sucediendo basándonos en los titulares que vemos de otras compañías. ¿Y cómo -- aparte de agregar estos clientes en IA, estoy seguro de que hay otras cosas geniales sucediendo, pero deberíamos esperar algunos cambios mayores en Broadcom como resultado de esto?

**Hock Tan**
Planteaste un -- un conjunto muy interesante de cuestiones y preguntas. Y esas son cuestiones muy relevantes e interesantes. El único problema -- el único problema que tenemos en este momento es, diría yo, que es realmente demasiado pronto para saber dónde vamos a parar todos. Quiero decir, esa es la amenaza, el ruido de los aranceles, especialmente sobre chips que aún no se ha materializado, ni sabemos cómo se estructurará. Así que no lo sabemos. Pero sí experimentamos y estamos dejando ahora la disrupción que es, de manera positiva, debo añadir, una disrupción muy positiva en los semiconductores sobre una IA generativa.

La IA generativa, sin duda, y lo dije antes también, a riesgo de repetirme aquí, pero es -- lo sentimos más que nunca. Realmente está acelerando el desarrollo de la tecnología de semiconductores, tanto en procesos y empaquetado como en diseño hacia aceleradores de mayor y mayor rendimiento y funcionalidad de redes. Estamos viendo esa innovación, esas actualizaciones ocurren cada mes a medida que enfrentamos nuevos e interesantes desafíos.

Y cuando -- particularmente con los XPUs, estamos tratando -- se nos ha pedido que optimicemos para los modelos de frontera de nuestros socios, nuestros clientes, así como nuestros socios hiperescaladores. Y nosotros -- es mucho -- quiero decir, es casi un privilegio para nosotros -- participar en ello e intentar optimizar. Y por optimizar, quiero decir, miras un acelerador, puedes mirarlo desde un término simple, de alto nivel para rendir -- para ser medido no solo en una única métrica, que es la capacidad de cómputo, cuántos teraflops. Es más que eso. También está ligado al hecho de que este es un problema de computación distribuida. No es solo la capacidad de cómputo de un solo XPU o GPU. También es el ancho de banda de la red. Se vincula al XPU o GPU adyacente más cercano. Así que eso tiene un impacto.

Así que estás haciendo eso, tienes que equilibrarlo con eso. Luego decides, ¿estás haciendo entrenamiento o estás haciendo pre-llenado? Post-entrenamiento, ajuste fino. Y de nuevo, luego viene cuánta memoria equilibras contra eso. Y con ello, cuánta latencia puedes permitirte, que es el ancho de banda de la memoria. Así que miras al menos 4 variables, quizás incluso 5 si incluimos en el ancho de banda de la memoria, no solo la capacidad de la memoria cuando vas directamente a la inferencia.

Así que tenemos todas estas variables con las que jugar. Y tratamos de optimizarlo. Así que todo esto es muy, muy -- quiero decir, es una gran experiencia para nuestros ingenieros empujar los límites sobre cómo crear todos esos chips. Y -- esa es la mayor disrupción que vemos ahora mismo, desde el simple intento de crear y empujar los límites en la IA generativa, tratando de crear la mejor infraestructura de hardware para ejecutarla.

Más allá de eso, hay otras cosas también que entran en juego porque con la IA, como indiqué, no solo impulsa el hardware para las empresas, sino que impulsa la forma en que arquitectan sus centros de datos. El requisito de datos -- mantener los datos privados bajo control se vuelve importante. Así que, de repente, el empuje de las cargas de trabajo hacia la nube pública puede

hacer una pequeña pausa mientras las grandes empresas, en particular, tienen que reconocer que quieren ejecutar cargas de trabajo de IA. Probablemente piensen muy seriamente en ejecutarlas on-premise.

Y de repente, te empujas a decir, tienes que actualizar tus propios centros de datos para hacer y gestionar tus propios datos para ejecutarlos on-premise. Y eso también está impulsando una tendencia que hemos estado viendo en los últimos 12 meses. De ahí mis comentarios sobre VMware Private AI Foundation. Esto es cierto, especialmente las empresas que impulsan la dirección están reconociendo rápidamente qué tan bien ejecutan sus cargas de trabajo de IA.

Así que esas son las tendencias que vemos hoy y mucho de ello proviene de la IA, mucho de ello proviene de reglas sensibles sobre soberanía en la nube y datos. En cuanto a los aranceles que mencionas, creo que es demasiado pronto para que nosotros averigüemos dónde vamos a parar todos. Y probablemente, quizás si le damos otros 3, 6 meses, probablemente tengamos una mejor idea de hacia dónde ir.

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de Ross Seymore con Deutsche Bank.

**Ross Seymore**
Hock, quiero volver al tema de los XPU. Y pasando de 4 nuevos compromisos, aún no clientes nombrados, 2 el último trimestre y 2 más hoy que anunciaste, quiero hablar sobre el paso del diseño a la implementación para juzgar eso, porque hay cierto debate sobre toneladas de victorias de diseño, pero las implementaciones en realidad no suceden, ya sea que nunca ocurran o que el volumen nunca sea el prometido originalmente. ¿Cómo ves ese tipo de ratio de conversión? ¿Hay un amplio rango alrededor de él? ¿O hay alguna manera en que podrías ayudarnos a entender cómo funciona eso?

**Hock Tan**
Bueno, Ross, pregunta interesante. Aprovecharé la oportunidad para decir que la forma en que vemos una victoria de diseño es probablemente muy diferente de la forma en que muchos de nuestros colegas la ven ahí fuera. Número uno, para empezar, creemos en la victoria de diseño cuando sabemos que nuestro producto se produce a escala -- a escala y se implementa realmente, literalmente implementado en producción. Así que eso lleva mucho tiempo porque desde el "taping out" (finalización del diseño), obtener el producto, lleva un año fácilmente desde que el producto está en manos de nuestro socio hasta que entra en producción a escala, llevará de 6 meses a un año según nuestra experiencia, eso hemos visto, número uno.

Y número dos, quiero decir, producir y desplegar 5.000 XPUs, eso es una broma. Eso no es producción real en nuestra opinión. Y por eso también nos limitamos a seleccionar socios que realmente necesiten ese gran volumen. Necesitas ese gran volumen desde nuestro punto de vista a escala ahora mismo, principalmente en entrenamiento, entrenamiento de grandes modelos de lenguaje, modelos de frontera en la trayectoria continua. Así que nos eliminamos a cuántos clientes o cuántos clientes potenciales existen ahí fuera, Ross, y tendemos a ser muy selectivos con quién elegimos para empezar.

Así que cuando decimos diseño, realmente es a escala. No es algo que comienza en 6 meses y muere en un año y muere de nuevo. Básicamente, es una selección de clientes. Es simplemente la forma en que hemos dirigido nuestro negocio de ASIC en general durante los últimos 15 años. Elegimos a los clientes porque sabemos esto y hacemos hojas de ruta plurianuales con estos clientes porque sabemos que estos clientes son sostenibles. Lo diré sin rodeos. No lo hacemos para start-ups.

**Operador(a)**
Y un momento para nuestra próxima pregunta, que vendrá de la línea de Stacy Rasgon con Bernstein Research.

**Stacy Rasgon**
Quería referirme a los 3 clientes que tienen en volumen hoy. Y lo que quería preguntar era, ¿hay alguna preocupación sobre algunas de las nuevas regulaciones o las reglas de difusión de IA que supuestamente se implementarán en mayo y que afecten alguna de esas victorias de diseño o envíos? Parece que piensan que los 3 siguen en pie en este momento, pero cualquier cosa que pudieran decirnos sobre si esas nuevas regulaciones o reglas de difusión de IA están afectando alguna de esas victorias sería útil.

**Hock Tan**
Gracias. En esta era o esta era actual de tensiones geopolíticas y acciones bastante dramáticas por parte de los gobiernos, siempre hay cierta preocupación en la mente de todos. Pero para responder directamente a tu pregunta, no, no tenemos ninguna preocupación.

**Stacy Rasgon**
Entendido. ¿Entonces ninguno de esos va a China o a clientes chinos?

**Hock Tan**
Sin comentarios. ¿Estás tratando de [indiscernible] quiénes son?

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de Vivek Arya con Bank of America.

**Vivek Arya**
Hock, siempre que has descrito tu oportunidad de IA, siempre has enfatizado la carga de trabajo de entrenamiento. Pero la percepción es que el mercado de IA podría estar dominado por la carga de trabajo de inferencia, especialmente con estos nuevos modelos de razonamiento. Entonces, ¿qué sucede con tu oportunidad y participación si la mezcla se mueve más hacia la inferencia? ¿Crea esto un TAM más grande para ti que los 60.000 a 90.000 millones de dólares? ¿Mantiene el mismo TAM pero hay una mezcla diferente de productos? ¿O un mercado más pesado en inferencia favorece a una GPU sobre un XPU?

**Hock Tan**
Esa es una buena -- pregunta interesante. Por cierto, nunca -- y sí hablo mucho sobre entrenamiento. Nuestros XPUs también se enfocan en la inferencia como una línea de productos separada. Lo hacen. Y es por eso que puedo decir que la arquitectura de esos chips es muy diferente de la arquitectura de los chips de entrenamiento. Y entonces es una combinación de esos 2, debo agregar, lo que suma estos 60.000 a 90.000 millones de dólares. Así que si no he sido claro, me disculpo, es una combinación de ambos. Pero dicho esto, la mayor parte de los dólares proviene del entrenamiento, no de la inferencia dentro del servicio, el SAM del que hemos hablado hasta ahora.

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de Harsh Kumar con Piper Sandler.

**Harsh Kumar**
Gracias equipo de Broadcom y, de nuevo, gran ejecución. Solo Hock, tenía una pregunta rápida. Hemos estado escuchando que casi todos los grandes clústeres que superan los 100.000, todos van a usar Ethernet. Me preguntaba si podrías ayudarnos a entender la importancia de cuándo el cliente está haciendo una selección, eligiendo entre alguien que tiene el mejor ASIC de switch como ustedes, versus alguien que podría tener el cómputo allí. ¿Puedes hablar sobre lo que el cliente está pensando y cuáles son los puntos finales que quieren alcanzar cuando hacen esa selección para las tarjetas NIC?

**Hock Tan**
Vale. No, es -- sí, se reduce a -- en el caso de los hiperescaladores ahora mismo, en gran medida, está impulsado por el rendimiento. Y su rendimiento, lo que mencionas sobre la conexión, el escalado hacia arriba y hacia afuera de esos aceleradores de IA, ya sean XPU o GPU entre los hiperescaladores. En la mayoría de los casos, entre esos hiperescaladores, nos involucramos cuando se trata de conectar esos clústeres. Están muy impulsados por el rendimiento. Quiero decir, si estás en una carrera para obtener realmente el mejor rendimiento de tu hardware mientras entrenas y continúas entrenando tus modelos de frontera, eso importa más que cualquier otra cosa.

Así que lo primero básico que buscan es que esté probado. Es una pieza de hardware probada. Es un sistema probado, un subsistema en nuestro caso, que funciona. Y en ese caso, tendemos a tener una gran ventaja porque, quiero decir, redes RS, conmutación y enrutamiento RS durante los últimos 10 años al menos. Y el hecho de que sea IA solo lo hace más interesante para que nuestros ingenieros trabajen en ello. Y -- pero básicamente se basa en tecnología probada y experiencia en impulsar eso -- y empujar los límites para pasar de un ancho de banda de 800 gigabits por segundo a 1.6, y avanzar a 3.2, que es exactamente por lo que seguimos aumentando la tasa de inversión en el desarrollo de nuestros productos donde tomamos Tomahawk 5. Duplicamos el radix para tratar con solo 1 hiperescalador porque quieren un alto radix para crear clústeres más grandes mientras ejecutan un ancho de banda que es más pequeño, pero eso no nos impide avanzar hacia la próxima generación de Tomahawk 6.

Y diría que incluso estamos planeando Tomahawk 7 y 8 en este momento y estamos acelerando el ritmo de desarrollo. Y todo es en gran medida para esos pocos tipos, por cierto. Así que estamos haciendo una gran inversión para muy pocos clientes, con suerte con mercados servidos disponibles muy grandes. Esa es -- si nada más, esa es la gran apuesta que estamos haciendo.

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de Timothy Arcuri con UBS.

**Timothy Arcuri**
Hock, en el pasado, has mencionado que las unidades XPU crecerán de aproximadamente 2 millones el año pasado a aproximadamente 7 millones, dijiste, en el plazo de 2027, 2028. Mi pregunta es, ¿estos 4 nuevos clientes, se suman a ese número de 7 millones de unidades? Sé que en el pasado, hablaste de un ASP (Precio Promedio de Venta) de 20.000 para entonces. Así que esos -- los primeros 3 clientes son claramente un subconjunto de esos 7 millones de unidades. ¿Estos nuevos 4 compromisos elevan esos 7 millones? ¿O simplemente completan para llegar a esos 7 millones?

**Hock Tan**
Gracias, Tim, por preguntar eso. Para aclarar, como yo -- pensé que lo había dejado claro en mis comentarios. No. El mercado del que estamos hablando, cuando traduces la unidad, es solo entre los 3 clientes que tenemos hoy. Los otros 4 de los que hablamos son socios de compromiso. No los consideramos clientes todavía, y por lo tanto no están en nuestro mercado servido disponible.

**Timothy Arcuri**
Vale. Así que se sumarían a ese número.

**Operador(a)**
Un momento para nuestra próxima pregunta, que vendrá de la línea de C.J. Muse con Cantor Fitzgerald.

**Christopher Muse**
Supongo, Hock, para seguir con tus comentarios preparados y comentarios anteriores sobre la optimización con tu mejor hardware y los hiperescaladores con su gran software. Tengo curiosidad por saber cómo estás expandiendo tu cartera ahora a 6 modelos de frontera a megaescala que te permitirán, y no te sonrojes, compartir información tremenda pero, al mismo tiempo, un mundo donde estos 6 realmente quieren diferenciarse. Obviamente, el objetivo para todos estos jugadores es exaflops por segundo por dólar de CapEx por vatio. Y supongo, ¿hasta qué punto los estás ayudando en estos esfuerzos? ¿Y dónde quizás comienza la "muralla china" (barrera de información) donde ellos quieren diferenciarse y no compartir contigo parte del trabajo que estás haciendo?

**Hock Tan**
Solo proporcionamos tecnología fundamental muy básica en semiconductores para permitir que estos tipos usen lo que tenemos y lo optimicen para sus modelos y algoritmos particulares que se relacionan con esos modelos. Eso es todo. Eso es todo lo que hacemos. Así que ese es el nivel de -- mucha de esa optimización la hacemos para cada uno de ellos. Y como mencioné antes, hay quizás 5 grados de libertad que hacemos. Y jugamos con eso. E incluso si hay 5 grados de libertad, solo podemos hacer hasta cierto punto. Pero es, y cómo ellos -- y básicamente cómo lo optimizamos, todo está ligado a que el socio nos diga cómo quieren hacerlo. Así que siempre hay mucho sobre lo que también tenemos visibilidad.

Pero lo que hacemos ahora es lo que el modelo XPU es, compartir optimización, traduciéndolo a rendimiento pero también a potencia, eso es muy importante, cómo lo juegan. No es solo el costo, aunque la potencia se traduce eventualmente en el costo total de propiedad. Es cómo lo diseñan en potencia y cómo lo equilibramos en términos del tamaño del clúster y si lo usan para entrenamiento, pre-entrenamiento, post-entrenamiento, inferencia, escalado en tiempo de prueba, todos ellos

tienen sus propias características. Y esa es la ventaja de hacer ese XPU y trabajar estrechamente con ellos para crear esas cosas.

Ahora, en cuanto a tu pregunta sobre China y todo eso, francamente, no tengo ninguna opinión al respecto. Para nosotros, es un juego técnico.

**Operador(a)**
Un momento para nuestra próxima pregunta, y vendrá de la línea de Christopher Rolland con Susquehanna.

**Christopher Rolland**
Y esta es quizás para Hock y para Kirsten. Me encantaría saber, ya que tienen la cartera completa de conectividad, cómo ven que se desarrollan aquí nuevas oportunidades de expansión "greenfield" (nuevas instalaciones) entre lo que podría ser óptico o cobre o realmente cualquier cosa, y qué aditivo podría ser esto para su empresa.

Y luego, Kirsten, creo que el OpEx (Gastos Operativos) ha aumentado. Quizás solo hables sobre hacia dónde se dirigen esos dólares de OpEx dentro de la oportunidad de IA y si se relacionan.

**Hock Tan**
Tu pregunta es muy amplia en nuestra cartera. Sí, tenemos la ventaja y muchos de los clientes hiperescaladores con los que tratamos, están hablando de mucha expansión. Pero es casi todo "greenfield", menos "brownfield" (instalaciones existentes). Es muy "greenfield". Es todo expansión, y todo tiende a ser de próxima generación lo que hacemos, lo cual es muy emocionante. Así que la oportunidad es muy, muy alta. Y estamos desplegando -- quiero decir, ambos -- podemos hacerlo en cobre. Pero donde vemos mucha oportunidad es cuando conectas -- proporcionas la conectividad de red a través de la óptica.

Así que hay muchos elementos activos, incluyendo ya sea láseres multimodo, que se llaman VCSELs, o láseres de emisión de borde para básicamente modo único, y hacemos ambos. Así que hay mucha oportunidad solo en escalar hacia arriba versus escalar hacia afuera. Solíamos hacer, todavía hacemos muchos otros protocolos más allá de Ethernet para considerar PCI Express, donde estamos a la vanguardia del PCI Express. Y la arquitectura en redes, conmutación, por así decirlo, ofrecemos ambos. Uno es un switch muy inteligente, que es como la familia Jericho con una NIC tonta o una NIC muy inteligente con un switch reducido, que es el Tomahawk. Ofrecemos ambas arquitecturas también.

Así que sí, tenemos muchas oportunidades a partir de ello. Dicho todo esto, toda esta bonita y amplia cartera y todo eso suma probablemente, como dije en trimestres anteriores, alrededor del 20% de nuestros ingresos totales de IA, quizás llegando al 30%. Aunque el último trimestre, alcanzamos casi el 40%, pero

eso no es la norma. Yo diría que, típicamente, todos esos otros productos de cartera todavía suman una buena cantidad decente de ingresos para nosotros.

Pero dentro de la esfera de la IA, suman, diría yo, en promedio, cerca del 30% y los XPUs, los aceleradores son el 70%. Si eso es lo que estás buscando, quizás eso te dé algo de -- arroje algo de luz sobre dónde -- cómo uno importa sobre el otro. Pero tenemos una amplia gama de productos en el lado de la conectividad, redes. Simplemente suman, sin embargo, a ese 30%.

**Kirsten Spears**
Y luego, en el frente de I+D, como describí, sobre una base consolidada, gastamos 1.400 millones de dólares en I+D en el Q1, y declaré que aumentaría en el Q2. Hock describió claramente en su guion las 2 áreas en las que nos estamos enfocando. Ahora te diré, como compañía, nos enfocamos en I+D en todas nuestras líneas de productos para que podamos seguir siendo competitivos con las ofertas de productos de próxima generación. Pero él sí expuso que nos estábamos enfocando en el "taping out" (finalización del diseño) del primer XPU de IA de 2 nanómetros de la industria empaquetado en 3D. Eso estaba en el guion, y esa es un área en la que nos estamos enfocando.

Y luego mencionó que hemos duplicado la capacidad de radix del Tomahawk existente para permitir a nuestros clientes de IA escalar en Ethernet hacia el millón de XPUs. Quiero decir, ese es un gran enfoque de la compañía.

**Operador(a)**
Y un momento para nuestra próxima pregunta, y viene de la línea de Vijay Rakesh con Mizuho.

**Vijay Rakesh**
Solo una pregunta rápida sobre el lado de las redes. ¿Me pregunto cuánto aumentó secuencialmente en el lado de la IA? ¿Y alguna idea sobre M&A (Fusiones y Adquisiciones) en el futuro, viendo muchos titulares sobre los productos de Intel, etcétera?

**Hock Tan**
Vale. En el lado de las redes, como indiqué, el Q1 mostró un cierto aumento, pero no espero que esa -- esa mezcla de 60-40, 60% es cómputo y 40% redes sea algo normal. Creo que la norma está más cerca de 70-30, quizás como mucho, 30%. Y quién sabe qué es el Q2, vemos el Q2 como una continuación, pero eso es solo, en mi opinión, un bache temporal. La norma será 70-30. Y si lo tomas a lo largo de un período de tiempo como 6 meses, un año, para responder a tu pregunta.

M&A, no, estoy demasiado ocupado. Estamos demasiado ocupados haciendo IA y VMware en este momento. No estamos pensando en ello en este momento.

**Operador(a)**
Gracias. Ese es todo el tiempo que tenemos para nuestra sesión de preguntas y respuestas. Ahora me gustaría devolver la llamada a Ji Yoo para cualquier comentario de cierre.

**Ji Yoo**
Gracias, Sheri. Broadcom actualmente planea reportar sus ganancias para el segundo trimestre del año fiscal 2025 después del cierre del mercado el jueves 5 de junio de 2025. Una transmisión pública por webcast de la conferencia telefónica de ganancias de Broadcom seguirá a las 2:00 p.m. Pacífico.
Esto concluirá nuestra llamada de ganancias de hoy. Gracias a todos por unirse. Sheri, puedes finalizar la llamada.

**Operador(a)**
Gracias. Damas y caballeros, gracias por participar. Esto concluye el programa de hoy. Pueden desconectarse ahora.